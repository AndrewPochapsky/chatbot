{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewPochapsky/chatbot/blob/master/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0I5A7ULV5Yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "from fastai.text import *\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import spacy\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS74TvsTbjQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = Path('drive/My Drive/datasets/cornell movie-dialogs corpus')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRhpvb63aYdk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e66d47a6-b5a8-4bab-f1de-b179aa9a7dc2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR2L2WOjZAVN",
        "colab_type": "text"
      },
      "source": [
        "# Training Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSrfFuwHaSgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "line_map = {}\n",
        "with open(base_path/'movie_lines.txt', encoding = 'ISO-8859-1') as f:\n",
        "    for line in f:\n",
        "        parts = line.split(' +++$+++ ')\n",
        "        line_num = parts[0]\n",
        "        #-2 to get rid of \\n\n",
        "        text = parts[-1][:-2]\n",
        "        line_map[line_num] = text\n",
        "      \n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4BHmalPi6JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table = []\n",
        "with open(base_path/'movie_conversations.txt', encoding = 'ISO-8859-1') as f:\n",
        "    for line in f:\n",
        "        parts = line.split(' +++$+++ ')\n",
        "        #get the referenced line numbers\n",
        "        line_nums = re.findall('L[0-9]+', parts[-1])\n",
        "        #form pairs\n",
        "        \n",
        "        for i in range(len(line_nums) - 1):\n",
        "            pair = (line_nums[i], line_nums[i+1])\n",
        "            #df.loc[df['column_name'] == some_value]\n",
        "            first = line_map[line_nums[i]]\n",
        "            second = line_map[line_nums[i+1]]\n",
        "            table.append([first, second])\n",
        "        \n",
        "            \n",
        "            \n",
        "data_df = pd.DataFrame(table, columns = ['in', 'out'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK6zOHYAjxtp",
        "colab_type": "code",
        "outputId": "6ebda577-ab4c-4b1f-81e2-8a1b04f4617a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>in</th>\n",
              "      <th>out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
              "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
              "      <td>Not the hacking and gagging and spitting part....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not the hacking and gagging and spitting part....</td>\n",
              "      <td>Okay... then how 'bout we try out some French ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
              "      <td>Forget it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
              "      <td>Cameron</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  in                                                out\n",
              "0  Can we make this quick?  Roxanne Korrine and A...  Well, I thought we'd start with pronunciation,...\n",
              "1  Well, I thought we'd start with pronunciation,...  Not the hacking and gagging and spitting part....\n",
              "2  Not the hacking and gagging and spitting part....  Okay... then how 'bout we try out some French ...\n",
              "3  You're asking me out.  That's so cute. What's ...                                          Forget it\n",
              "4  No, no, it's my fault -- we didn't have a prop...                                            Cameron"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc78yc7jY3To",
        "colab_type": "text"
      },
      "source": [
        "# Word2Vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTVhRWBJkSbX",
        "colab_type": "text"
      },
      "source": [
        "Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lthfvrbqY7hF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "d35fbe4c-3fc5-45b8-8706-e88eca0769e0"
      },
      "source": [
        "def preprocess(s):\n",
        "    s = s.replace('\\n',' ').lower()\n",
        "    return s\n",
        "\n",
        "def tokenize(corpus):\n",
        "    tokenizer = spacy.blank(\"en\").tokenizer\n",
        "    doc = tokenizer(corpus)\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "        if(token.text.strip() != \"\"):\n",
        "            tokens.append(token.text)\n",
        "    return tokens\n",
        "\n",
        "def process_dataset():\n",
        "    all_words = \"\"\n",
        "    with open(base_path/'movie_lines.txt', encoding = 'ISO-8859-1') as f:\n",
        "        for line in f:\n",
        "            parts = line.split(' +++$+++ ')\n",
        "            all_words += parts[-1]\n",
        "    return all_words\n",
        "\n",
        "def generate_vocab(tokens, min_freq = 0):\n",
        "    all_unique_words_counter = Counter(tokens)\n",
        "    vocab = {}\n",
        "    index = 0\n",
        "    for w in all_unique_words_counter.keys():\n",
        "        if(all_unique_words_counter[w] >= min_freq and w.strip() != \"\"):\n",
        "            vocab[w] = index\n",
        "            index += 1\n",
        "    return vocab\n",
        "\n",
        "#TODO: figure out how to only take words that appear at least x times\n",
        "def create_training_matrices(vocab, all_words, window_size = 5):\t\n",
        "\t\n",
        "\tnumTotalWords = len(all_words)\n",
        "\txTrain=[]\n",
        "\tyTrain=[]\n",
        "\tfor i in range(numTotalWords):\n",
        "\t\tif i % 100000 == 0:\n",
        "\t\t\tprint ('Finished %d/%d total words' % (i, numTotalWords))\n",
        "\t\twordsAfter = all_words[i + 1:i + window_size + 1]\n",
        "\t\twordsBefore = all_words[max(0, i - window_size):i]\n",
        "\t\twordsAdded = wordsAfter + wordsBefore\n",
        "\t\tfor word in wordsAdded:\n",
        "\t\t\txTrain.append(vocab[all_words[i]])\n",
        "\t\t\tyTrain.append(vocab[word])\n",
        "\treturn xTrain, yTrain\n",
        "\n",
        "full_corpus = process_dataset() \n",
        "full_corpus = preprocess(full_corpus)\n",
        "print('Begin Tokenization')\n",
        "tokens = tokenize(full_corpus) # list of string\n",
        "print('Generating vocab')\n",
        "vocab = generate_vocab(tokens)\n",
        "print('Getting training data')\n",
        "x_train, y_train = create_training_matrices(vocab, tokens)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin Tokenization\n",
            "Generating vocab\n",
            "Getting training data\n",
            "Finished 0/4194111 total words\n",
            "Finished 100000/4194111 total words\n",
            "Finished 200000/4194111 total words\n",
            "Finished 300000/4194111 total words\n",
            "Finished 400000/4194111 total words\n",
            "Finished 500000/4194111 total words\n",
            "Finished 600000/4194111 total words\n",
            "Finished 700000/4194111 total words\n",
            "Finished 800000/4194111 total words\n",
            "Finished 900000/4194111 total words\n",
            "Finished 1000000/4194111 total words\n",
            "Finished 1100000/4194111 total words\n",
            "Finished 1200000/4194111 total words\n",
            "Finished 1300000/4194111 total words\n",
            "Finished 1400000/4194111 total words\n",
            "Finished 1500000/4194111 total words\n",
            "Finished 1600000/4194111 total words\n",
            "Finished 1700000/4194111 total words\n",
            "Finished 1800000/4194111 total words\n",
            "Finished 1900000/4194111 total words\n",
            "Finished 2000000/4194111 total words\n",
            "Finished 2100000/4194111 total words\n",
            "Finished 2200000/4194111 total words\n",
            "Finished 2300000/4194111 total words\n",
            "Finished 2400000/4194111 total words\n",
            "Finished 2500000/4194111 total words\n",
            "Finished 2600000/4194111 total words\n",
            "Finished 2700000/4194111 total words\n",
            "Finished 2800000/4194111 total words\n",
            "Finished 2900000/4194111 total words\n",
            "Finished 3000000/4194111 total words\n",
            "Finished 3100000/4194111 total words\n",
            "Finished 3200000/4194111 total words\n",
            "Finished 3300000/4194111 total words\n",
            "Finished 3400000/4194111 total words\n",
            "Finished 3500000/4194111 total words\n",
            "Finished 3600000/4194111 total words\n",
            "Finished 3700000/4194111 total words\n",
            "Finished 3800000/4194111 total words\n",
            "Finished 3900000/4194111 total words\n",
            "Finished 4000000/4194111 total words\n",
            "Finished 4100000/4194111 total words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFoU81ng2MXd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dffdee3f-2b7b-4b99-af1a-6ad6e09c60db"
      },
      "source": [
        ""
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41941080"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avoAJTVmuGPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}